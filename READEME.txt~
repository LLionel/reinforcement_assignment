本项目环境：Ubuntu 16.04，python 3.5，pytorch 0.2.0.post3，matplotlib 2.1.0，numpy 1.13.3。实验的是基于Gym 0.9.4。

Q-learning运行方法:
    1.CartPole：进入src/QLearning目录下，在终端中输入： python cartpole1.py
    2.Mountain car：进入src/QLearning目录下，在终端中输入： python mountain_car1.py
    3.Acrobot：进入src/QLearning目录下，在终端中输入： python acrobotv1.py

DQN:
    1.CartPole：进入src/DQN目录下，在终端中输入： python cartpole.py
    2.Mountain car：进入src/DQN目录下，在终端中输入： python mountain_car.py
    3.Acrobot：进入src/DQN目录下，在终端中输入： python acrobot.py
improved DQN:
    1.CartPole：进入src/improvedDQN目录下，在终端中输入： python cartpole.py
    2.Mountain car：进入src/improvedDQN目录下，在终端中输入： python mountain_car.py
    3.Acrobot：进入src/improvedDQN目录下，在终端中输入： python acrobot.py


Note: 具体实验中DQN和Improved DQN 并没有调参，效果并不是很好。

更多细节请看 details.pdf
